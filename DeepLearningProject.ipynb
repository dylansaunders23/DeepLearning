{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ba60615ec2f48a7b4f825f5d0f11804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45431b11d21044a5b1d48e9b2a5c5b0e",
              "IPY_MODEL_b45bd94759a6488f81e065d069dd721c",
              "IPY_MODEL_69af026e2cb340fbb2ed30d735e32897"
            ],
            "layout": "IPY_MODEL_3a81730fa7ef411383bb7e489d563c7f"
          }
        },
        "45431b11d21044a5b1d48e9b2a5c5b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_836b1635839e41498c32f738376edfcf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8d1311dc03d14ff9a7b8edbee3a04c40",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡â€‡25%"
          }
        },
        "b45bd94759a6488f81e065d069dd721c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d58e7d42afb24e56a0adcc3cd51d1165",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ca79794e95e46508d2ebe4f3cc31d13",
            "value": 1
          }
        },
        "69af026e2cb340fbb2ed30d735e32897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad6e68edf06b4e4791abdae0e4286795",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7b187b128fde424198253ac89ee1b5cd",
            "value": "â€‡1/4â€‡[00:25&lt;01:17,â€‡25.73s/it]"
          }
        },
        "3a81730fa7ef411383bb7e489d563c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "836b1635839e41498c32f738376edfcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d1311dc03d14ff9a7b8edbee3a04c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d58e7d42afb24e56a0adcc3cd51d1165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca79794e95e46508d2ebe4f3cc31d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad6e68edf06b4e4791abdae0e4286795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b187b128fde424198253ac89ee1b5cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylansaunders23/DeepLearning/blob/main/DeepLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Lyrics"
      ],
      "metadata": {
        "id": "oxmKGfJKy5NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **PART 1: Load Data**"
      ],
      "metadata": {
        "id": "VKheYK_4y6R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data from Kaggle Datasource"
      ],
      "metadata": {
        "id": "8cHeqCX4nOso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "hz2AchaVzJ9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9421e36d-05e9-4c36-cf73-8f12fe9ddf09"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npH_cURPzcQi",
        "outputId": "2db64d18-c47a-4bdd-a57b-6210c5ce6111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "f01tYh7o16bg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea07a4c3-e23f-4993-cf0d-276cca9394d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/root/.kaggleâ€™: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "h7vQqZG24DZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "hyEPFZqU4gVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d juicobowley/drake-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgDyG1TP49Os",
        "outputId": "a73e44c5-4eee-4777-9d05-614a05615773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/juicobowley/drake-lyrics\n",
            "License(s): other\n",
            "drake-lyrics.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d suraj520/music-dataset-song-information-and-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DDbBHqiou7K",
        "outputId": "3303b6b0-6647-43ee-c825-38a1df09cb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/suraj520/music-dataset-song-information-and-lyrics\n",
            "License(s): CC0-1.0\n",
            "music-dataset-song-information-and-lyrics.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip drake-lyrics.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bED2ZFPb5uDi",
        "outputId": "53ec97f9-4fbc-43af-c961-87139fcb1466"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drake-lyrics.zip\n",
            "replace drake_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip music-dataset-song-information-and-lyrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Egi5DgIo1dW",
        "outputId": "52dcfe64-ef62-4d58-9647-148c195283e7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  music-dataset-song-information-and-lyrics.zip\n",
            "replace songs.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse the lyrics to get a list of words"
      ],
      "metadata": {
        "id": "2Se5n2WQnV3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "# NOTE:\n",
        "# need to download the 'punkt' and 'stopwords' depndencies from nltk, used by\n",
        "# tokenize and stopworks respectively:\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRPyTqBeAXeO",
        "outputId": "bf3bd5e3-f718-4138-fca9-8202ff3062e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "other_dataset = pd.read_csv('/content/songs.csv')\n",
        "drake_dataset = pd.read_csv('/content/drake_data.csv')"
      ],
      "metadata": {
        "id": "tpS8IMQopSjJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other artists"
      ],
      "metadata": {
        "id": "luro7HnEp9aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  if isinstance(text, str):\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    # Remove anything in brackets or parenthesis\n",
        "    text = re.sub(r'\\[.*?\\]', '', text)  # Removes contents inside square brackets []\n",
        "\n",
        "    # Remove anything in brackets or parenthesis\n",
        "    text = re.sub(\"[\\]]\", \"\", text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    return text\n",
        "  else:\n",
        "    return ''"
      ],
      "metadata": {
        "id": "0i2KdAdfVyc5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_first_line(text):\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Join the lines, excluding the first one\n",
        "    new_text = '\\n'.join(lines[1:])\n",
        "\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "_5YEme5cTWJQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(dataset):\n",
        "  lyrics = []\n",
        "  for i in dataset['Lyrics']:\n",
        "\n",
        "    lyrics_only = remove_first_line(i)\n",
        "    lyrics += [preprocess_text(lyrics_only)]\n",
        "\n",
        "  return lyrics"
      ],
      "metadata": {
        "id": "vJ6CTHImabBw"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other_lyrics = process_text(other_dataset)\n"
      ],
      "metadata": {
        "id": "xdEnGQiMRkoF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drake Lyrics"
      ],
      "metadata": {
        "id": "4zXZcUfhqDGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drake_lyrics = []\n",
        "\n",
        "for i in drake_dataset.lyrics:\n",
        "  drake_lyrics += [preprocess_text(i)]"
      ],
      "metadata": {
        "id": "xYplvULZ7C8i"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "print(drake_lyrics[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgpeT3bxbmPq",
        "outputId": "90396f5e-8a17-46b8-ed7b-1434932c3e7a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hands are tied\n",
            "Someones in my ear from the other side\n",
            "Tellin me that I should pay you no mind\n",
            "Wanted you to not be with me all night\n",
            "Wanted you to not stay with me all night\n",
            "I know you know who that person is to me\n",
            "Doesnt really change things\n",
            "\n",
            "\n",
            "I know youre scared of dating falling for me\n",
            "Shorty surely you know me\n",
            "Right here for you always\n",
            "You know I dont ever change\n",
            "Right here for you always\n",
            "You know I dont ever change\n",
            "Right here for you\n",
            "\n",
            "\n",
            "In mind you make me want to do things love you\n",
            "Like Im supposed to\n",
            "You make me want to love you\n",
            "Like Im supposed to\n",
            "You make me want to love you\n",
            "Like Im supposed to remind you\n",
            "Ayy\n",
            "\n",
            "\n",
            "I know youre scared of dating falling for me\n",
            "Shorty by now you know me\n",
            "Right here for you always\n",
            "You know I dont ever change\n",
            "Right here for you always\n",
            "You know I dont ever change\n",
            "Right here for you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "print(other_lyrics[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIoBLtyi8Lcb",
        "outputId": "b0076bde-ac7f-46f2-bf34-dffa51544dd6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "We skipped the light fandango\n",
            "Turned cartwheels cross the floor\n",
            "I was feeling kinda seasick\n",
            "But the crowd called out for more\n",
            "The room was humming harder\n",
            "As the ceiling flew away\n",
            "When we called out for another drink\n",
            "The waiter brought a tray\n",
            "\n",
            "\n",
            "And so it was that later\n",
            "As the miller told his tale\n",
            "That her face at first just ghostly\n",
            "Turned a whiter shade of pale\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "She said there is no reason\n",
            "And the truth is plain to see\n",
            "But I wandered through my playing cards\n",
            "And would not let her be\n",
            "One of sixteen vestal virgins\n",
            "Who were leaving for the coast\n",
            "And although my eyes were open\n",
            "They might have just as wellve been closed\n",
            "You might also like\n",
            "And so it was that later\n",
            "As the miller told his tale\n",
            "That her face at first just ghostly\n",
            "Turned a whiter shade of pale\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "She said Im home on shore leave\n",
            "Though in truth we were at sea\n",
            "So I took her by the looking glass\n",
            "And forced her to agree\n",
            "Saying You must be the mermaid\n",
            "Who took Neptune for a ride\n",
            "But she smiled at me so sadly\n",
            "That my anger straightway died\n",
            "\n",
            "\n",
            "And so it was that later\n",
            "As the miller told his tale\n",
            "That her face at first just ghostly\n",
            "Turned a whiter shade of pale\n",
            "\n",
            "If music be the food of love\n",
            "Then laughter is its queen\n",
            "And likewise if behind is in front\n",
            "Then dirt in truth is clean\n",
            "My mouth by then like cardboard\n",
            "Seemed to slip straight through my head\n",
            "So we crashdived straightway quickly\n",
            "And attacked the ocean bed\n",
            "\n",
            "And so it was that later\n",
            "As the miller told his tale\n",
            "That her face at first just ghostly\n",
            "Turned a whiter shade of pale16Embed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both songs processed lyrics with stop words"
      ],
      "metadata": {
        "id": "fXpTm6s0nctJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to create a list of all of the lyrics and tokenize them"
      ],
      "metadata": {
        "id": "wkZ1PAPPnkve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelWithLMHead\n",
        "\n",
        "HUGGINGFACE_UAT=\"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\"\n",
        "login(HUGGINGFACE_UAT)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
        "\n",
        "model_name = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
      ],
      "metadata": {
        "id": "WwQPJJuSAuGb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "4ba60615ec2f48a7b4f825f5d0f11804",
            "45431b11d21044a5b1d48e9b2a5c5b0e",
            "b45bd94759a6488f81e065d069dd721c",
            "69af026e2cb340fbb2ed30d735e32897",
            "3a81730fa7ef411383bb7e489d563c7f",
            "836b1635839e41498c32f738376edfcf",
            "8d1311dc03d14ff9a7b8edbee3a04c40",
            "d58e7d42afb24e56a0adcc3cd51d1165",
            "9ca79794e95e46508d2ebe4f3cc31d13",
            "ad6e68edf06b4e4791abdae0e4286795",
            "7b187b128fde424198253ac89ee1b5cd"
          ]
        },
        "outputId": "ac91511a-3f14-4aac-de84-61f4669e92d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ba60615ec2f48a7b4f825f5d0f11804"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_drake, temp_drake = train_test_split(drake_lyrics,test_size=0.2)\n",
        "val_drake, test_drake = train_test_split(temp_drake,test_size=0.5)\n",
        "print(len(train_drake), len(val_drake), len(test_drake))\n",
        "\n",
        "train_other, temp_other = train_test_split(other_lyrics,test_size=0.2)\n",
        "val_other, test_other = train_test_split(temp_other,test_size=0.5)\n",
        "print(len(train_other), len(val_other), len(test_other))"
      ],
      "metadata": {
        "id": "HIaD45OUD4Gy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "b777631f-3d82-409c-c2b7-829de6aed68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drake_lyrics' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dd442c5a6ec3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_drake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_drake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrake_lyrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_drake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_drake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_drake\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_drake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_drake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_drake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'drake_lyrics' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('trainDrake.txt', 'w') as f:\n",
        "  for t in train_drake:\n",
        "    f.write(t)\n",
        "    f.write(' ')\n",
        "\n",
        "\n",
        "with open('testDrake.txt', 'w') as f:\n",
        "  for t in test_drake:\n",
        "    f.write(t)\n",
        "    f.write(' ')\n",
        "\n",
        "train_drake_path = 'trainDrake.txt'\n",
        "test_drake_path = 'testDrake.txt'\n",
        "\n",
        "with open('trainOther.txt', 'w') as f:\n",
        "  for t in train_other:\n",
        "    f.write(t)\n",
        "    f.write(' ')\n",
        "\n",
        "\n",
        "with open('testOther.txt', 'w') as f:\n",
        "  for t in test_other:\n",
        "    f.write(t)\n",
        "    f.write(' ')\n",
        "\n",
        "train_other_path = 'trainOther.txt'\n",
        "test_other_path = 'testOther.txt'"
      ],
      "metadata": {
        "id": "Wn600ArBlVX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator\n",
        "\n",
        "train_drake_dataset,test_drake_dataset,data_drake_collator = load_dataset(train_drake_path,test_drake_path,tokenizer)\n",
        "train_other_dataset,test_other_dataset,data_other_collator = load_dataset(train_other_path,test_other_path,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arKM7-M2l_uj",
        "outputId": "5e4341ea-8e50-4608-9841-ee68dcf36139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-diomedes-2\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=300,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    eval_steps = 100,\n",
        "    save_steps=800,\n",
        "    warmup_steps=500\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_drake_collator,\n",
        "    train_dataset=train_drake_dataset,\n",
        "    eval_dataset=test_drake_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "UIhYllIdnSlU",
        "outputId": "fb7300ff-695b-4f1d-d295-086160d97660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AutoModelWithLMHead' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-151-be6d2799d928>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args = TrainingArguments(\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./gpt2-diomedes-2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AutoModelWithLMHead' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will create sequences from each lyric to the next, stopped by the end of the song"
      ],
      "metadata": {
        "id": "81AJlk_qn0w_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(tokens, tokenized_sequence):\n",
        "  sequences = []\n",
        "\n",
        "  for i in range (0, len(tokenized_sequence) - 3):\n",
        "      curr  = tokens[i]\n",
        "      next1 = tokens[i+1]\n",
        "      next2 = tokens[i+2]\n",
        "      next3 = tokens[i+3]\n",
        "      # If neither token is the end-of-song marker, add it to the current sequence\n",
        "      if curr != 'ENDOFSONG' and next1 != 'ENDOFSONG' and next2 != 'ENDOFSONG' and next3 != 'ENDOFSONG':\n",
        "          sequences.append([tokenized_sequence[i], tokenized_sequence[i+1], tokenized_sequence[i+2], tokenized_sequence[i+3]])\n",
        "\n",
        "\n",
        "  # Convert sequences to numpy array\n",
        "  sequences = np.array(sequences)\n",
        "\n",
        "  # Split sequences into input (X) and output (Y)\n",
        "  X = sequences[:, :-1]\n",
        "  Y = sequences[:, -1]\n",
        "\n",
        "  # Split the dataset into training (80%), validation (10%), and test (10%) sets\n",
        "  X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.2)\n",
        "  X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5)\n",
        "\n",
        "  return X_train, X_val, X_test, Y_train, Y_val, Y_test"
      ],
      "metadata": {
        "id": "TQfQSpksLY7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_drake, X_val_drake, X_test_drake, Y_train_drake, Y_val_drake, Y_test_drake = split_data(tokens, tokenized_sequence)"
      ],
      "metadata": {
        "id": "a63XLZ-Si2yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_other, X_val_other, X_test_other, Y_train_other, Y_val_other, Y_test_other = split_data(tokens2, tokenized_sequence2)"
      ],
      "metadata": {
        "id": "kbsHbR_CjBqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train_other), len(X_val_other), len(X_test_other))\n",
        "print(len(Y_train_other), len(Y_val_other), len(Y_test_other))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSmMXdqpxh9f",
        "outputId": "fb41396e-09c2-4df1-d418-e8d37e297388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80174 10022 10022\n",
            "80174 10022 10022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train_drake), len(X_val_drake), len(X_test_drake))\n",
        "print(len(Y_train_drake), len(Y_val_drake), len(Y_test_drake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab18hAelxphN",
        "outputId": "622f9cad-f572-4c01-9e27-e15298866dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59982 7498 7498\n",
            "59982 7498 7498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Model"
      ],
      "metadata": {
        "id": "bAvfpj3vPnjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "\n",
        "# Define the LSTM model\n",
        "def create_model(vocabulary_size, seq_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 50, input_length=seq_length))\n",
        "    model.add(LSTM(100, return_sequences=True))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Train the LSTM model\n",
        "def train_model(X_train, Y_train, X_val, Y_val, vocab_size):\n",
        "    model = create_model(vocab_size, X_train.shape[1])\n",
        "    model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=300)\n",
        "    return model\n",
        "\n",
        "# Evaluate the trained model on the test set\n",
        "def evaluate_model(model, X_test, Y_test):\n",
        "    loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "    print('Test Accuracy: %.2f%%' % (accuracy*100))\n",
        "\n",
        "# For Drake's lyrics\n",
        "model_drake = train_model(X_train_drake, Y_train_drake, X_val_drake, Y_val_drake, len(tokenizer.word_index)+1)\n",
        "evaluate_model(model_drake, X_test_drake, Y_test_drake)\n",
        "\n",
        "# For other dataset lyrics\n",
        "model_other = train_model(X_train_other, Y_train_other, X_val_other, Y_val_other, len(tokenizer2.word_index)+1)\n",
        "evaluate_model(model_other, X_test_other, Y_test_other)"
      ],
      "metadata": {
        "id": "WOIvW3YCx9Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180d5fbf-4b91-4273-8a8d-0cee152a902a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 50)             424150    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 100)            60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8483)              856783    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1431833 (5.46 MB)\n",
            "Trainable params: 1431833 (5.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 34s 146ms/step - loss: 7.6119 - accuracy: 0.0238 - val_loss: 7.3105 - val_accuracy: 0.0289\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 31s 153ms/step - loss: 7.1471 - accuracy: 0.0268 - val_loss: 7.3564 - val_accuracy: 0.0289\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 7.1104 - accuracy: 0.0268 - val_loss: 7.3967 - val_accuracy: 0.0291\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 29s 148ms/step - loss: 7.0838 - accuracy: 0.0268 - val_loss: 7.4320 - val_accuracy: 0.0285\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 30s 150ms/step - loss: 7.0415 - accuracy: 0.0269 - val_loss: 7.4824 - val_accuracy: 0.0328\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 6.9714 - accuracy: 0.0327 - val_loss: 7.4898 - val_accuracy: 0.0335\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 28s 141ms/step - loss: 6.8751 - accuracy: 0.0337 - val_loss: 7.5295 - val_accuracy: 0.0372\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 6.7623 - accuracy: 0.0376 - val_loss: 7.4765 - val_accuracy: 0.0404\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 29s 147ms/step - loss: 6.6324 - accuracy: 0.0408 - val_loss: 7.5044 - val_accuracy: 0.0385\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 30s 148ms/step - loss: 6.5024 - accuracy: 0.0433 - val_loss: 7.6121 - val_accuracy: 0.0429\n",
            "Test Accuracy: 4.40%\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 3, 50)             524300    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 3, 100)            60400     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10486)             1059086   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1734286 (6.62 MB)\n",
            "Trainable params: 1734286 (6.62 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "268/268 [==============================] - 49s 166ms/step - loss: 7.7320 - accuracy: 0.0164 - val_loss: 7.5050 - val_accuracy: 0.0159\n",
            "Epoch 2/10\n",
            "268/268 [==============================] - 44s 163ms/step - loss: 7.3025 - accuracy: 0.0175 - val_loss: 7.5186 - val_accuracy: 0.0168\n",
            "Epoch 3/10\n",
            "268/268 [==============================] - 44s 163ms/step - loss: 7.1671 - accuracy: 0.0253 - val_loss: 7.3361 - val_accuracy: 0.0319\n",
            "Epoch 4/10\n",
            "268/268 [==============================] - 43s 159ms/step - loss: 6.8849 - accuracy: 0.0368 - val_loss: 7.2518 - val_accuracy: 0.0350\n",
            "Epoch 5/10\n",
            "268/268 [==============================] - 43s 159ms/step - loss: 6.6599 - accuracy: 0.0404 - val_loss: 7.1896 - val_accuracy: 0.0385\n",
            "Epoch 6/10\n",
            "268/268 [==============================] - 43s 159ms/step - loss: 6.4565 - accuracy: 0.0477 - val_loss: 7.1813 - val_accuracy: 0.0439\n",
            "Epoch 7/10\n",
            "268/268 [==============================] - 43s 160ms/step - loss: 6.2513 - accuracy: 0.0563 - val_loss: 7.1662 - val_accuracy: 0.0507\n",
            "Epoch 8/10\n",
            "268/268 [==============================] - 42s 158ms/step - loss: 6.0559 - accuracy: 0.0645 - val_loss: 7.1987 - val_accuracy: 0.0607\n",
            "Epoch 9/10\n",
            "268/268 [==============================] - 42s 157ms/step - loss: 5.8559 - accuracy: 0.0764 - val_loss: 7.2715 - val_accuracy: 0.0687\n",
            "Epoch 10/10\n",
            "268/268 [==============================] - 41s 154ms/step - loss: 5.6417 - accuracy: 0.0905 - val_loss: 7.3224 - val_accuracy: 0.0763\n",
            "Test Accuracy: 8.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8Wldocc3Pc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}